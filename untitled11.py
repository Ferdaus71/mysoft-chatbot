# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CWoKZJnYvTDMP72e82Y-DdQ9RGm8yFqe
"""

!pip install langchain langchain-community langchain-openai
!pip install faiss-cpu gradio tiktoken openai

from google.colab import files
uploaded = files.upload()

!pip install pypdf langchain-text-splitters
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

documents = []

for file in uploaded.keys():
    loader = PyPDFLoader(file)
    documents.extend(loader.load())

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100
)

chunks = text_splitter.split_documents(documents)

print("Total Chunks:", len(chunks))

from google.colab import userdata
import os

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

!pip install sentence-transformers
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# Using a free, high-quality open-source model
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

vectorstore = FAISS.from_documents(chunks, embeddings)

vectorstore.save_local("mysoft_index")
print("Vector store created and saved successfully using HuggingFace!")

import os

print("API key loaded:", os.environ.get("OPENAI_API_KEY") is not None)
print("Model:", os.environ.get("MODEL_NAME"))

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

def ask_mysoft(question):
    template = """
    You are an AI assistant for Mysoft Heaven (BD) Ltd.

    Answer ONLY using the provided company information below.
    If the answer is not found in the context, say:
    "Sorry, this information is not available in Mysoft Heaven (BD) Ltd. documents."

    Company Context:
    {context}

    Question:
    {question}
    """

    prompt = ChatPromptTemplate.from_template(template)

    chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    return chain.invoke(question)

def ask_mysoft_with_confidence(question):
    docs_and_scores = vectorstore.similarity_search_with_score(question, k=3)

    if len(docs_and_scores) == 0:
        return "No relevant information found.", 0

    avg_score = sum([score for _, score in docs_and_scores]) / len(docs_and_scores)

    if avg_score > 1.0:   # threshold (tune if needed)
        return "Sorry, this question seems unrelated to Mysoft Heaven (BD) Ltd.", 0

    context = "\n\n".join([doc.page_content for doc, _ in docs_and_scores])

    prompt = f"""
You are an AI assistant for Mysoft Heaven (BD) Ltd.

Strictly answer from context.
If not available, say not available.

Context:
{context}

Question:
{question}
"""

    response = llm.invoke(prompt)

    confidence = round(1 - avg_score, 2)

    return response.content, confidence

chat_history = []

def chat_with_memory(question):
    global chat_history

    response, confidence = ask_mysoft_with_confidence(question)

    chat_history.append((question, response))

    return response + f"\n\nConfidence Score: {confidence}"

pip install streamlit langchain langchain-community langchain-openai faiss-cpu pypdf openai

import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from google.colab import userdata

# -------------------------------
# ðŸ”‘ SET YOUR OPENAI KEY
# -------------------------------
os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

st.title("Mysoft Heaven (BD) Ltd. AI Chatbot")

# -------------------------------
# ðŸ“‚ Upload Documents
# -------------------------------
uploaded_file = st.file_uploader("Upload Company PDF", type="pdf")

if uploaded_file:
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.read())

    loader = PyPDFLoader("temp.pdf")
    documents = loader.load()

    # -------------------------------
    # âœ‚ Chunking Strategy
    # -------------------------------
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100
    )

    chunks = text_splitter.split_documents(documents)

    # -------------------------------
    # ðŸ” Embeddings + FAISS
    # -------------------------------
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_documents(chunks, embeddings)

    st.success("Document Processed Successfully âœ…")

    # -------------------------------
    # ðŸ’¬ Chat Section
    # -------------------------------
    question = st.text_input("Ask about Mysoft Heaven (BD) Ltd:")

    if question:
        docs_and_scores = vectorstore.similarity_search_with_score(question, k=3)

        if len(docs_and_scores) == 0:
            st.warning("No relevant information found.")
        else:
            avg_score = sum([score for _, score in docs_and_scores]) / len(docs_and_scores)

            # ðŸš« Out-of-scope handling
            if avg_score > 1.5:
                st.error("Sorry, this question is outside company documents.")
            else:
                context = "\n\n".join([doc.page_content for doc, _ in docs_and_scores])

                llm = ChatOpenAI(
                    model="gpt-4o-mini",
                    temperature=0
                )

                prompt = f"""
You are an AI assistant for Mysoft Heaven (BD) Ltd.

Strictly answer ONLY from the context below.
If answer is not available, say:
"This information is not available in company documents."

Context:
{context}

Question:
{question}
"""

                response = llm.invoke(prompt)
                answer = response.content if hasattr(response, "content") else str(response)
                confidence = round(1 - avg_score, 2)

                st.write("### ðŸ“Œ Answer:")
                st.write(answer)
                st.write(f"### ðŸ”Ž Confidence Score: {confidence}")

import os

os.environ["MODEL_NAME"] = "gpt-4o-mini"
os.environ["TEMPERATURE"] = "0.3"
os.environ["MAX_TOKENS"] = "800"

import os

print("API key loaded:", os.environ.get("OPENAI_API_KEY") is not None)
print("Model:", os.environ.get("MODEL_NAME"))

import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from google.colab import userdata

# ==========================================
#  SET YOUR OPENAI API KEY
# ==========================================
# Using Colab secrets for security
os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

# ==========================================
#  PAGE CONFIG
# ==========================================
st.set_page_config(page_title="Mysoft Heaven AI Chatbot", layout="wide")
st.title(" Mysoft Heaven (BD) Ltd. AI Chatbot")
st.write("This chatbot answers strictly from uploaded company documents.")

# ==========================================
#  Upload Company Documents
# ==========================================
uploaded_files = st.file_uploader(
    "Upload Mysoft Heaven Company PDFs",
    type="pdf",
    accept_multiple_files=True
)

# ==========================================
#  Session Memory
# ==========================================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if uploaded_files:
    documents = []
    for uploaded_file in uploaded_files:
        with open(uploaded_file.name, "wb") as f:
            f.write(uploaded_file.read())
        loader = PyPDFLoader(uploaded_file.name)
        documents.extend(loader.load())

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100
    )
    chunks = text_splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_documents(chunks, embeddings)

    st.success(" Documents processed and indexed successfully!")

    question = st.text_input("Ask your question about Mysoft Heaven (BD) Ltd:")

    if question:
        docs_and_scores = vectorstore.similarity_search_with_score(question, k=3)
        if len(docs_and_scores) == 0:
            st.error(" No relevant company information found.")
        else:
            avg_score = sum([score for _, score in docs_and_scores]) / len(docs_and_scores)
            if avg_score > 1.5:
                st.warning(" Sorry, this question is outside Mysoft Heaven (BD) Ltd. documents.")
            else:
                context = "\n\n".join([doc.page_content for doc, _ in docs_and_scores])
                llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
                prompt = f"""
You are an AI assistant for Mysoft Heaven (BD) Ltd.

Rules:
- Answer ONLY using the provided context.
- If answer is not found, say:
  "This information is not available in company documents."
- Do NOT use external knowledge.

Context:
{context}

Question:
{question}
"""
                response = llm.invoke(prompt)
                answer = response.content if hasattr(response, "content") else str(response)
                confidence = round(1 - avg_score, 2)
                st.session_state.chat_history.append((question, answer))
                st.subheader(" Answer")
                st.write(answer)
                st.subheader(" Confidence Score")
                st.write(confidence)

    if st.session_state.chat_history:
        st.subheader(" Conversation History")
        for q, a in st.session_state.chat_history:
            st.write(f"**Q:** {q}")
            st.write(f"**A:** {a}")
            st.write("---")

import os

print("API key loaded:", os.environ.get("OPENAI_API_KEY") is not None)
print("Model:", os.environ.get("MODEL_NAME"))